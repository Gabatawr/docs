# The Oldest Game - LLM Benchmark

## Суть
Состязательный бенчмарк для тестирования логического мышления, аргументации и детекта противоречий в LLM.

## Почему это хороший бенчмарк

### Проверяемые навыки

**1. Логика:**
- Причинно-следственные связи (копьё убивает тигра ✓ / копьё убивает надежду ✗)
- Физические законы (огонь жжёт дерево ✓ / огонь жжёт камень ✗)
- Контр-меры (вода тушит огонь ✓ / вода питает огонь ✗)

**2. Абстракция:**
- Переход между уровнями (материальное → силы → метаобразы)
- Понимание когда можно эскалировать
- Связь конкретного и абстрактного

**3. Креативность в рамках:**
- Генерация контр-мер без читинга
- Баланс между оригинальностью и логичностью
- Избегание тупиковых ходов

**4. Детект противоречий:**
- Распознавание нелегальных скачков силы
- Выявление слабой логики противника
- Защита собственных аргументов

**5. Аргументация:**
- Обоснование челленджа
- Защита оспоренного хода
- Контр-аргументация

### Преимущества перед другими бенчмарками

| Бенчмарк | Что тестирует | Ограничения |
|----------|---------------|-------------|
| MMLU | Знания | Нет рассуждений |
| GSM8K | Математика | Узкая область |
| HumanEval | Код | Только программирование |
| **Oldest Game** | **Состязательное рассуждение** | **Комплексно** |

**Уникальность:**
- Проверяет логику + креативность + аргументацию одновременно
- Состязательный формат (LLM vs LLM)
- Самопроверка через челлендж-механику
- Минимальный контекст (~500 токенов активного окна)

## Механика валидации через челлендж

### Поток хода

```
1. Игрок А делает ход:
   "я огонь, пожирающий тигра"

2. Игрок Б (выбор):
   a) "логично" → принимает, делает свой ход
   b) "не логично: тигр быстрее и убежит от огня"

3. Если оспорил (вариант b), Игрок А (выбор):
   a) "согласен, не логично" → поражение
   b) "логично т.к.: я окружил тигра стеной огня, он в ловушке"

4. Судья (третий LLM или человек) анализирует аргументы:
   → Если оспаривание обосновано: А проиграл
   → Если защита убедительна: Б получает штраф
```

### Система штрафов

**За необоснованный челлендж:**
- Вариант 1: Лимит попыток (3 за игру)
- Вариант 2: Штрафные очки (-1 балл)
- Вариант 3: Потеря права челленджа на N ходов

**Цель штрафов:**
- Предотвратить спам оспариваний
- Риск за необдуманные претензии
- Баланс между проверкой и доверием

### Роль судьи

**Оценивает:**
1. Логичность исходного хода (А)
2. Обоснованность претензии (Б)
3. Убедительность защиты (А)
4. Выносит вердикт + объяснение

**Критерии:**
- Соответствие физике/биологии/логике
- Плавность эскалации (нет скачков)
- Убедительность аргументов
- Полнота объяснений

## Условия победы/поражения

**Поражение когда:**
1. Не смог защитить свой ход после челленджа
2. Зашёл в логический тупик (не может ответить)
3. Время на ход вышло (30-60 сек)
4. Кончились попытки челленджа и пропустил фатальный ход

**Без челленджа проблема:**
- Бесконечная абстракция: "я X" → "я мета-X" → "я супер-мета-X"...
- Побеждает креативность формулировок, не логика
- Нет естественного конца

**Челлендж решает:**
- Принудительная проверка спорных ходов
- Победа через аргументацию
- Три навыка: придумать контр + распознать слабость + защитить позицию

## Метрики для бенчмарка

### Для каждой модели измеряем:

**Логика:**
- % валидных ходов (принятых без челленджа)
- % успешных защит после оспаривания
- Средняя длина цепочки до ошибки

**Детект:**
- % обоснованных челленджей (подтверждённых судьёй)
- % необоснованных челленджей (ложные тревоги)
- Precision/Recall на детект слабой логики

**Аргументация:**
- % успешных защит оспоренных ходов
- Качество объяснений (оценка судьи)
- Убедительность контр-аргументов

**Креативность:**
- Разнообразие концептов
- Оригинальность решений
- Избегание повторов

**Общее:**
- Win rate в турнире LLM vs LLM
- Средняя длина партии
- Уровень эскалации (до какого слоя доходят)

## Форматы тестирования

### 1. LLM vs LLM турнир
- Round-robin (каждый с каждым)
- Измерение win rate
- Выявление стратегий

### 2. LLM vs Human
- Насколько убедительна для людей
- Человек как судья
- Сравнение с человеческой логикой

### 3. LLM как судья
- Третья модель судит споры
- Проверка способности взвешивать аргументы
- Сравнение судейских решений разных моделей

### 4. Специализированные тесты
- Только материальный уровень (L1)
- Только абстракции (L3)
- Ограниченная тематика (только природа / только технологии)

## Датасет

**Генерация:**
- Запустить турниры LLM vs LLM (1000+ партий)
- Собрать все ходы + челленджи + судейские решения
- Разметить валидность/невалидность

**Использование:**
- Обучение моделей на паттернах
- Тест-сет для новых моделей
- База концептов и их взаимодействий

**Эволюция:**
- Постоянное пополнение новыми партиями
- Сложность растёт с улучшением моделей
- Adversarial examples из необычных партий

## Преимущества для бенчмарка

**Экономичность:**
- Минимальный контекст (~500 токенов активного окна)
- На 200k влезает 400+ полных партий
- Можно компрессировать историю

**Масштабируемость:**
- Легко генерировать неограниченное количество партий
- Автоматическое судейство через третью модель
- Параллельные турниры

**Объективность:**
- Чёткие критерии победы/поражения
- Измеримые метрики
- Воспроизводимые результаты

**Глубина:**
- Не решается запоминанием
- Требует настоящего понимания
- Проверяет рассуждение, не знания
